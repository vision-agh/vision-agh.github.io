<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> NCN Preludium | Embedded Vision Systems Group </title> <meta name="author" content=" "> <meta name="description" content=""> <meta name="keywords" content="Event CamerasEvent-based OdometryUAVsEmbedded PlatformsDeep Neural Networks"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?e3a7352ea63996f57fd2f1dbd16a81e5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon-32x32.png?526825e930ccc4741e4ea207a6e61fc0"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://vision-agh.github.io/projects/preludium_wasala"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a href="/" class="active"> <img src="/assets/img/logo_evs_group.png" alt="Embedded Vision Systems Group"> </a> <a class="navbar-brand title font-weight-lighter" href="/"> Embedded Vision Systems Group </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/team">Team </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Papers </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repos </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">NCN Preludium</h1> <p class="post-description"></p> </header> <article> <h2 class="flex items-center mb-1 text-lg font-semibold text-gray-900">EEVONN:Embedded Event-Based Visual Odometry Using Neural Networks </h2> <h3 class="block mb-2 text-sm font-normal leading-none text-gray-500 ">EEVONN:Wbudowana odometria wizyjna wykorzystująca sieci neuronowe oraz dane zdarzeniowe </h3> <p class="mt-4 mb-0"> <span class="font-semibold ml-4">Principal Investigator:</span> <a href="/members/wasala">Msc Mateusz Wąsala </a> </p> <p class="mt-0 mb-0"> <span class="font-semibold ml-4">Project Duration:</span> 28 January 2026 - 28 January 2028 </p> <p class="mt-0 mb-4"> <span class="font-semibold ml-4">Budget:</span> 136640 PLN </p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/preludium_MW_short_scheme-480.webp 480w,/assets/img/projects/preludium_MW_short_scheme-800.webp 800w,/assets/img/projects/preludium_MW_short_scheme-1400.webp 1400w," type="image/webp" sizes="95vw"> <img src="/assets/img/projects/preludium_MW_short_scheme.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Scheme" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> </div> <div class="caption"> </div> <span class="font-semibold mt-4">Abstract:</span> <p> Position and motion estimation is a key challenge in autonomous navigation of unmanned aerial vehicles (UAVs), especially in environments where GPS signals are unavailable, degraded, or unreliable - such as indoor spaces, tunnels, dense forests, areas with strong electromagnetic interference, or in space and planetary exploration missions. In such conditions, infrastructure-independent localization methods based solely on onboard sensors - such as cameras, lidars, or inertial measurement units (IMUs) - are essential. The difficulty increases in highly dynamic scenarios where conventional frame-based cameras exhibit significant limitations due to motion blur, poor resilience to changing lighting conditions, and high energy and computational demands. A promising alternative is offered by event cameras - neuromorphic vision sensors that operate asynchronously and register only pixel-level changes in brightness. The event stream they generate offers high temporal resolution and a wide dynamic range (HDR) while significantly reducing energy consumption and eliminating motion blur. These characteristics make event cameras an ideal component for UAV perception systems operating in harsh or non-cooperative environments, including extra-terrestrial settings where reliability and energy efficiency are crucial. The objective of the present project is to develop innovative perception and navigation methodologies for UAVs that leverage event-based vision and energy-efficient heterogeneous System-on-Chip Field-Programmable Gate Array (SoC FPGA) platforms. These platforms integrate general-purpose processors (CPUs) with reconfigurable logic fabric (FPGAs), enabling real-time, low-power, on-device data processing in a compact form factor with minimal energy requirements. A key focus of this study is to investigate capabilities and limitations of hardware-aware implementations of event-based visual odometry algorithms on embedded platforms. While current research predominantly concentrates on algorithmic aspects, it often neglects hardware efficiency and power constraints. This project addresses that knowledge gap by proposing architectural and algorithmic modifications that enable hardware-optimised position estimation based on event data. The research will involve the design of specialised neural network architectures adapted to the unique characteristics of event data, including graph neural networks (GNNs) and spiking neural networks (SNNs), which more accurately capture its spatiotemporal structure. These models will undergo a process of miniaturization and simplification in accordance with the TinyML (Tiny Machine Learning) paradigm. This is done to ensure compatibility with hardware that is limited in resources while maintaining the quality of inference. In order to reduce computational and memory demands, advanced quantisation techniques for weights and activations will be applied, thus minimising numerical precision without a significant loss of accuracy. Concurrently, pivotal neural network operations – including matrix multiplications and convolutions – will be optimised with respect to the architectural intricacies of FPGA-based hardware. The final outcome of the project will be a set of integrated hardware-software modules implementing a complete event-based UAV navigation system, covering the entire processing pipeline from data acquisition to trajectory estimation. In order to demonstrate the practical feasibility of the developed solutions, a functional system demonstrator will be constructed. The findings will be presented in journals and scientific conferences, and part of the code will be made available in an open repository. This research will not only address the scientific challenges posed by processing event camera data but also contribute to the development of more efficient vision systems for mobile robotics, enhancing their safety and reliability. </p> <div class="more-info-keywords mt-4 mb-4 flex flex-wrap gap-1"> <span class="text-xs px-2 py-1 rounded">Deep Neural Networks</span> <span class="text-xs px-2 py-1 rounded">Embedded Platforms</span> <span class="text-xs px-2 py-1 rounded">Event Cameras</span> <span class="text-xs px-2 py-1 rounded">Event-based Odometry</span> <span class="text-xs px-2 py-1 rounded">UAVs</span> </div> </article> <h3 id="publications" class="mt-6 mb-6 font-bold text-center">Publications</h3> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div id="badap-agh:148543" class="col-sm-12"> <div class="abbr"> <abbr class="badge project"><a href="/projects/ncn">Preludium <i class="fas fa-external-link-alt"></i></a></abbr><br> </div> <div class="title">Detection-segmentation convolutional neural network for autonomous vehicle perception</div> <div class="author"> Maciej Baczmanski, Robert Synoczek, <a href="/members/wasala">Mateusz Wasala</a>, and <a href="/members/kryjak">Tomasz Kryjak</a> </div> <div class="periodical"> <em>In </em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/MMAR58394.2023.10242398" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> </div> </div> </li> <li> <div class="row"> <div id="badap-agh:149007" class="col-sm-12"> <div class="abbr"> <abbr class="badge project"><a href="/projects/ncn">Preludium <i class="fas fa-external-link-alt"></i></a></abbr><br> </div> <div class="title">Implementation of a perception system for autonomous vehicles using a detection-segmentation network in SoC FPGA</div> <div class="author"> Maciej Baczmanski, <a href="/members/wasala">Mateusz Wasala</a>, and <a href="/members/kryjak">Tomasz Kryjak</a> </div> <div class="periodical"> <em>In </em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1007/978-3-031-42921-7_14" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 . </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>